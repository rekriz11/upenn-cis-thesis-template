In this chapter, we first present a novel Seq2Seq framework for sentence simplification. We contribute three major improvements over generic Seq2Seq models: a complexity-weighted loss function to encourage the model to choose simpler words; a similarity penalty during inference and clustering post-inference, to generate candidate simplifications with significant differences; and a re-ranking system to select the simplification that promotes both fluency and adequacy. Our model outperforms previous state-of-the-art systems according to SARI, the standard metric for simplification used in our evaluation, while we highlight the issues with the current automatic metrics. More importantly, while previous models generate relatively long sentences, our model is able to generate shorter and simpler sentences, while remaining competitive regarding human-evaluated fluency and adequacy. Finally, we provide a qualitative analysis of the improvements introduced by our specific contributions, discuss the effect of sentence length on human-evaluated meaning preservation, and the shortcomings of our model as insights for future research.

In the second part of this chapter, we present Simple-QE, a quality estimation model for simplification. We have shown that extending Sum-QE \citep{xenouleas2019sumqe} to include the reference complex sentence significantly improves predictions on Adequacy and Complexity. QE systems can be useful for evaluating the overall quality of model output without requiring expensive human annotations or references. Future simplification systems can incorporate Simple-QE into the optimization process, similar to how SARI was incorporated into a Seq2Seq network \citep{zhang2017sentence}.

From the modifications we applied to standard Seq2Seq architectures, we found that the ones that improved performance on sentence simplification were incorporating a diverse decoding strategy, followed by re-ranking the resulting candidates. As we note, our methodology for sentence simplification is only one of many strategies that have recently been developed, as many open-ended language generation tasks can greatly benefit from multiple unique but valid candidate outputs. In the following chapter, we further pursue this idea of diversity, and perform an exhaustive comparison of current diverse decoding techniques on two tasks: conversational dialogue systems and image captioning. While these tasks have different goals than sentence simplification, all three fields share the fact that they benefit from re-ranking or combining diverse candidate outputs.